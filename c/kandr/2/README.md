# 2

## 2.3, Constants

The usual. Skipped the first two parts cause didn't really want ot need them.
This is the shit maaaan let me tell ya.

So this was something interesting. Working with converting int to char and back
and forth. A char can be broken down into numbers. Char can be converted to int,
int can be converted to char.

No matter what number you enter you can get a result of some character value.
Does this work with unicode? Does unicode provide these character numbers? How
the heck can I even use unicode in C?

Figure out how to use unicode. Right, right, right. Have to figure out a way to
do this the correct way. If you don't stop and don't have gaps, you will
remember these things, and you will move very far very quickly.

Immersed in this world. For some kind of safety and whatnot? Here it is safe,
everything is safe. World of the terminal. Twitter client. Secure, personal
twitter client using twitter API. Write it in go. What about an email client?

I think I new this already, but the reason that you can compare characters is
because they have an ascii numerical value.

Its true that you have wasted time. You don't have to make an excuse for
yourself. No need to pity yourself.

Remember that you cannot size things based on what inputs you send through,
unless you dynamically allocate the stuff.

### Enums

Defaults to settings each item in the list to some integer + 1. Can also group
other variable declataions in here.

## Type Conversions

You can convert between long to short ints without any errors, but it will give
you warnings (dependent on implementation I guess).

Char is just a type of int according to this book. It is just an int without
very much. That is, its a very small int or something. Unicode, anybody?

### Ctypes

First mention of Ctypes. Ctypes provides functions for checking for things, like
if a thing is a digit and turning something into lower case.

We don't necessarily now whether chars are unsigned or signed integers, and this
may be dependant on the machine itself.

As you suspected, in all tests, if it is anything but NULL then it works. Zero
is NULL.

If you have two operators of a lower and higher type, the lower type is
converted to the higher type.

Floats in an expression are not automatically converted to doubles. Math
functions, like those in <math.h> use doubles. There are two reasons to use
floats over doubles: 1) to save space in large arrays, and 2) to save
computation time if you are having to compute a huge number of doubles.

I want to do what I do better than anyone else. What I do is my special
combination of the skills I have and the things I know. Other people will have
similar such skills, and similar knowledge, but I want to be the best at doing
those things and knowing those things.

Does casting only really work for number types? That would make sense I think...

## Increments

I added all the relevant info in increments_and_decrements.c. Not too much
interesting here.

## Bitwise Operators

Bitwise operators can only be used with integers, not floats. Chars though it
can be used with.

& - and
| - or
^ - xor
<< - left shift
>> - right_shift
~ - complement

